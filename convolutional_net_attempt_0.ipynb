{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pk\n"
     ]
    }
   ],
   "source": [
    "print('pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "#imports:\n",
    "# !pip install\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from datagenerator import *\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# constants:\n",
    "SIZE = 170\n",
    "RESIZED_WIDTH = SIZE  # temp\n",
    "RESIZED_HEIGHT = SIZE  # temp\n",
    "RESIZED_NUM_PIXELS = RESIZED_WIDTH * RESIZED_HEIGHT\n",
    "SHAPE = RESIZED_NUM_PIXELS + 3\n",
    "TRAIN_PATH = r'.\\train'  # temp\n",
    "VALID_PATH = r'.\\test'  # temp\n",
    "TEST_PATH = r'.\\validation'  # temp\n",
    "BACH_SIZE = 18 # temp\n",
    "TRAIN_DATASET_SIZE = dataset_size(TRAIN_PATH)\n",
    "VALID_DATASET_SIZE = dataset_size(VALID_PATH)\n",
    "TEST_DATA_SIZE = dataset_size(TEST_PATH)\n",
    "STEPS_PER_EPOCH = TRAIN_DATASET_SIZE // BACH_SIZE\n",
    "EPOCHS = 2 # temp\n",
    "VALIDATION_STEPS = VALID_DATASET_SIZE // BACH_SIZE\n",
    "TEST_STEPS = TEST_DATA_SIZE // BACH_SIZE\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import PIL as pl\n",
    "def data_generator(path):\n",
    "    i=0\n",
    "    images=[]\n",
    "    vol=[]\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            vol.append(get_volt_from_img_name(name))\n",
    "    while i<=len(range(1,len(vol))):\n",
    "        try:\n",
    "            yield {'image':np.array(pl.Image.open(os.path.join(root,files[i-1]))), 'voltage_data':[vol[i],vol[i-1],vol[i]-vol[i-1]]}, np.array(pl.Image.open(os.path.join(root,files[i])))\n",
    "            i+=1\n",
    "        except StopIteration:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Either `output_signature` or `output_types` must be specified",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-194-c1f47618857f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# activating data gen:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mx_train_generator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_generator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_generator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# validation_generator = data_generator(VALID_PATH, BACH_SIZE,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m#                                       True, RESIZED_WIDTH, RESIZED_HEIGHT)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    536\u001B[0m                 \u001B[1;34m'in a future version'\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mdate\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;34m'after %s'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mdate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    537\u001B[0m                 instructions)\n\u001B[1;32m--> 538\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    539\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    540\u001B[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001B[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001B[0m in \u001B[0;36mfrom_generator\u001B[1;34m(generator, output_types, output_shapes, args, output_signature)\u001B[0m\n\u001B[0;32m    820\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    821\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0moutput_types\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 822\u001B[1;33m         raise TypeError(\"Either `output_signature` or `output_types` must \"\n\u001B[0m\u001B[0;32m    823\u001B[0m                         \"be specified\")\n\u001B[0;32m    824\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: Either `output_signature` or `output_types` must be specified"
     ]
    }
   ],
   "source": [
    "# activating data gen:\n",
    "x_train_generator = tf.data.Dataset.from_generator(data_generator)\n",
    "\n",
    "# validation_generator = data_generator(VALID_PATH, BACH_SIZE,\n",
    "#                                       True, RESIZED_WIDTH, RESIZED_HEIGHT)\n",
    "# test_generator = data_generator(TEST_PATH, BACH_SIZE,\n",
    "#                                 True, RESIZED_WIDTH, RESIZED_HEIGHT)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-188-cacc467c72f9>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     27\u001B[0m               \u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlosses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSparseCategoricalCrossentropy\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m               metrics=['accuracy'])\n\u001B[1;32m---> 29\u001B[1;33m model.fit(x=x_train_generator,\n\u001B[0m\u001B[0;32m     30\u001B[0m           \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mEPOCHS\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m           steps_per_epoch=STEPS_PER_EPOCH)\n",
      "\u001B[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1048\u001B[0m          \u001B[0mtraining_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mRespectCompiledTrainableState\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1049\u001B[0m       \u001B[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1050\u001B[1;33m       data_handler = data_adapter.DataHandler(\n\u001B[0m\u001B[0;32m   1051\u001B[0m           \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1052\u001B[0m           \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1099\u001B[0m     \u001B[0madapter_cls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mselect_data_adapter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1100\u001B[1;33m     self._adapter = adapter_cls(\n\u001B[0m\u001B[0;32m   1101\u001B[0m         \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1102\u001B[0m         \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001B[0m\n\u001B[0;32m    796\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mtensor_shape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensorShape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;32mNone\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    797\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 798\u001B[1;33m     \u001B[0moutput_shapes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_get_dynamic_shape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpeek\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    799\u001B[0m     \u001B[0moutput_types\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpeek\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36mmap_structure\u001B[1;34m(func, *structure, **kwargs)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    661\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m   return pack_sequence_as(\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[0mstructure\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mentries\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m       expand_composites=expand_composites)\n\u001B[0;32m    661\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36m_get_dynamic_shape\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    790\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    791\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_get_dynamic_shape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 792\u001B[1;33m       \u001B[0mshape\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    793\u001B[0m       \u001B[1;31m# Unknown number of dimensions, `as_list` cannot be called.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    794\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mshape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrank\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'float' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as K\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "image=L.Input((RESIZED_WIDTH,RESIZED_HEIGHT,1))\n",
    "voltage_data=L.Input((3))\n",
    "\n",
    "\n",
    "# conv branch\n",
    "conv = L.Conv2D(filters=1, kernel_size=1, activation=\"sigmoid\")(image)\n",
    "conv = L.Conv2D(filters=1, kernel_size=1, activation=\"sigmoid\")(conv)\n",
    "conv = L.Conv2D(filters=1, kernel_size=1, activation=\"sigmoid\")(conv)\n",
    "conv_flat = L.Flatten()(conv)\n",
    "conv_out = L.Concatenate(axis=1)([conv_flat,voltage_data])\n",
    "flat_hidden = L.Dense(units=128, activation=\"sigmoid\")(conv_out)\n",
    "flat_hidden = L.Dense(units=128, activation=\"sigmoid\")(flat_hidden)\n",
    "flat_hidden = L.Dense(units=128, activation=\"sigmoid\")(flat_hidden)\n",
    "flat_hidden = L.Dense(units=128, activation=\"sigmoid\")(flat_hidden)\n",
    "flat_hidden = L.Dense(units=128, activation=\"sigmoid\")(flat_hidden)\n",
    "flat_out = L.Dense(units=128, activation=\"sigmoid\")(flat_hidden)\n",
    "# comb\n",
    "comb_out = L.Dense(units=RESIZED_NUM_PIXELS, activation=\"sigmoid\")(flat_out)\n",
    "\n",
    "# conv branch\n",
    "model = K.Model(inputs=[image,voltage_data] , outputs=comb_out)\n",
    "# model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train_generator,\n",
    "          epochs=EPOCHS,\n",
    "          steps_per_epoch=STEPS_PER_EPOCH)\n",
    "print('ok')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating the Model:\n",
    "test_loss = model.evaluate(test_generator, steps=TEST_STEPS)\n",
    "print('Test loss:', test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "######## functions for visualizing predictions ########\n",
    "\n",
    "def visualize_prediction(pred_input, original_output, prediction):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
    "\n",
    "    # Plot the input frame.\n",
    "    ax = axes[0]\n",
    "    ax.imshow(np.squeeze(pred_input), cmap=\"gray\")\n",
    "    ax.set_title(f\"input\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Plot the original new frame.\n",
    "    ax = axes[1]\n",
    "    ax.imshow(np.squeeze(original_output), cmap=\"gray\")\n",
    "    ax.set_title(f\"original output\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Plot the new frame.\n",
    "    ax = axes[2]\n",
    "    ax.imshow(np.squeeze(prediction), cmap=\"gray\")\n",
    "    ax.set_title(f\"predicted output\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Display the figure.\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def predict_and_save(path_for_saving: str, num_pf_predictions: int = None):\n",
    "    if num_pf_predictions is None:\n",
    "        num_pf_predictions = TEST_DATA_SIZE\n",
    "    next_test = next_data(TEST_PATH, RESIZED_WIDTH, RESIZED_HEIGHT)\n",
    "    for _ in range(num_pf_predictions):\n",
    "        pred_input, original_output = next(next_test)\n",
    "        prediction_output = model.predict(np.array([pred_input]))\n",
    "        prediction = img_from_output(prediction_output[0], RESIZED_WIDTH, RESIZED_HEIGHT)\n",
    "        my_input = img_from_input(pred_input,RESIZED_WIDTH,RESIZED_HEIGHT)\n",
    "        original_output = img_from_output(original_output,RESIZED_WIDTH,RESIZED_HEIGHT)\n",
    "        #saving:\n",
    "        join = os.path.join\n",
    "        volts = pred_input[-3:]\n",
    "        name = f'{volts[0]}_{volts[1]}_{volts[2]}'\n",
    "        os.mkdir(join(path_for_saving, name))\n",
    "        for img_name, img in zip(['prediction.png', 'input.png', 'original_output.png'],\n",
    "                                 [prediction, my_input, original_output]):\n",
    "            cv2.imwrite(join(path_for_saving, name, img_name), img)\n",
    "\n",
    "\n",
    "def show_me_random_unsaved_predictions():\n",
    "    next_test = next_data(TEST_PATH, RESIZED_WIDTH, RESIZED_HEIGHT)\n",
    "    while True:\n",
    "        pred_input, original_output = next(next_test)\n",
    "        prediction_output = model.predict(np.array([pred_input]))\n",
    "        prediction = img_from_output(prediction_output[0], RESIZED_WIDTH, RESIZED_HEIGHT)\n",
    "        my_input = img_from_input(pred_input, RESIZED_WIDTH, RESIZED_HEIGHT)\n",
    "        original_output = img_from_output(original_output, RESIZED_WIDTH, RESIZED_HEIGHT)\n",
    "        visualize_prediction(my_input, original_output, prediction)\n",
    "        que = input('press_enter_for_anther_prediction, type q to break')\n",
    "        if que == 'q':\n",
    "            print('breaking...')\n",
    "            break\n",
    "\n",
    "\n",
    "def show_me_random_saved_predictions(saved_predictions_path: str):\n",
    "    predictions_list = os.listdir(saved_predictions_path)\n",
    "    random.shuffle(predictions_list)\n",
    "    join = os.path.join\n",
    "    for pred in predictions_list:\n",
    "        my_input = cv2.imread(join(saved_predictions_path, pred, 'input.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        original_output = cv2.imread(join(saved_predictions_path, pred, 'original_output.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        prediction = cv2.imread(join(saved_predictions_path, pred, 'prediction.png'), cv2.IMREAD_GRAYSCALE)\n",
    "        visualize_prediction(my_input, original_output, prediction)\n",
    "        que = input('press_enter_for_anther_prediction, type q to break')\n",
    "        if que == 'q':\n",
    "            print('breaking...')\n",
    "            break\n",
    "    print('There are no more predictions')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predict_and_save('H:\\hadars_folder\\predictions1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_me_random_unsaved_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}